[
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects Overview",
    "section": "",
    "text": "Description: Pick a dataset and explore it to discover insights and answer questions.\n\n\n\nDescription: Find an interesting data source, collect the data, and prepare it for analysis.\n\n\n\nDescription: A comprehensive project that shows off my data science skills.",
    "crumbs": [
      "Projects Overview"
    ]
  },
  {
    "objectID": "projects/index.html#all-projects",
    "href": "projects/index.html#all-projects",
    "title": "Projects Overview",
    "section": "",
    "text": "Description: Pick a dataset and explore it to discover insights and answer questions.\n\n\n\nDescription: Find an interesting data source, collect the data, and prepare it for analysis.\n\n\n\nDescription: A comprehensive project that shows off my data science skills.",
    "crumbs": [
      "Projects Overview"
    ]
  },
  {
    "objectID": "projects/eda.html",
    "href": "projects/eda.html",
    "title": "",
    "section": "",
    "text": "Code",
    "crumbs": [
      "eda.html"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Welcome to my data science portfolio! This site shows my journey learning data science and analytics. Here you’ll find projects that demonstrate what I’ve learned and discovered.\n\n\nThis portfolio shows my work learning data science. Each project includes:\n\nMy code with documentation\nVisualizations I created\nWhat I learned and discovered\n\nI built this site using Quarto and host it on GitHub Pages.\n\n\n\n\nProgramming: Python for data analysis and structures, R for statistical data analysis, etc.\nVisualization: Creating charts with Matplotlib, Seaborn, Power BI, and Tableau\nData Collection: Getting data from files, websites, and APIs\nAnalysis: Finding patterns and answering questions with data which I’ve tidied and wrangled.\n\n\n\n\n\n\n\nLearn how I explore datasets to find interesting patterns and answer questions.\n\n\n\nSee how I gather data from different sources and prepare it for analysis.\n\n\n\nSee how I tackle a data science project beginning to end.\n\n\n\nThanks for visiting! Feel free to explore my projects and see what I’m learning."
  },
  {
    "objectID": "index.html#about-this-portfolio",
    "href": "index.html#about-this-portfolio",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "This portfolio shows my work learning data science. Each project includes:\n\nMy code with documentation\nVisualizations I created\nWhat I learned and discovered\n\nI built this site using Quarto and host it on GitHub Pages."
  },
  {
    "objectID": "index.html#skills-im-learning",
    "href": "index.html#skills-im-learning",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Programming: Python for data analysis and structures, R for statistical data analysis, etc.\nVisualization: Creating charts with Matplotlib, Seaborn, Power BI, and Tableau\nData Collection: Getting data from files, websites, and APIs\nAnalysis: Finding patterns and answering questions with data which I’ve tidied and wrangled."
  },
  {
    "objectID": "index.html#my-projects",
    "href": "index.html#my-projects",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Learn how I explore datasets to find interesting patterns and answer questions.\n\n\n\nSee how I gather data from different sources and prepare it for analysis.\n\n\n\nSee how I tackle a data science project beginning to end.\n\n\n\nThanks for visiting! Feel free to explore my projects and see what I’m learning."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Excited to be part of the growing data science and machine learning fields, I combine my technology skills with my interpersonal skills to bring meaningful analyses and insights out of big data.\nYears of experience and training in the field of door-to-door Sales and Network Marketing gave me the skills and attributes necessary to cultivate quality client relations, communicate clearly, and bring optimism and positivity to my workplace. I consistently strive toward self improvement and can apply my intellect and ethic to any task. It is said that 90% of workplaces desire sales skills/sales experience, but less than 10% of workers possess those skills.\nStatistics major, Data Science Emphasis, Senior, interest in Machine Learning, Neural Networks, creative business solutions, agentic AI.\n\n\n\n\nBrigham Young University\nBachelor’s of Applied Science, Statistics\nApril, 2026\n\n\n\n\n\nData Analyst, TELUS International AI Data Solutions.\n\nAnalysts for TELUS International assist in training AI. A specific rating system is given for analysts to apply to various queries and usage cases. Combining responsibilities for discerning best ratings with adhesion to high quality standards, analysts must process queries to make the AI more accurate and useful.\n\n\n\n\nAssessment Team, Office of Belonging, BYU - Working in tools like MAXQDA, Excel, Power BI, and R, analyzed non-ordinal and unstructured survey data to extract insight from focus groups and student demographics, improving outreach and furthering the mission of the office.\n\n\n\nWhat affects NBA draft chances? - Group Research Project, Fall 2024 - Experimental Design, Data Wrangling, Statistical Modeling - Used R (Tidyverse, ggplot2) and NCAA basketball APIs to collect and clean collegiate athlete data - Built hybrid multiple regression model to identify predictive draft factors; found player position had more impact than traditionally valued statistics (e.g., PPG or RPG) - Co-led data visualization and storytelling for final team presentation\nDo Wash Cycles affect clothing shrinkage? - Group Research Project, Winter 2024 - Experiment Design, Collection of Data, Statistical Modeling - Designed and conducted a controlled experiment with 3 fabric types across different wash cycles - Analyzed shrinkage patterns using R and Tableau; visualized trends and presented findings in class - Demonstrated measurable though impact of wash cycle settings on shrinkage, even with pre-shrunk fabrics\n\n\n\n\n\n\n\nR, Python, SQL, HTML/CSS, C++, VBA\n\n\n\n\n\nNumPy, Pandas, Sci-Kit Learn, Tidyverse, NoSQL, Linux, Tableau, Power BI, MAXQDA, Excel\n\n\n\n\n\nData wrangling, data visualization, statistical analysis, multiple regression, linear models, logistic regression, machine learning, linear algebra, hypothesis testing, agentic AI\n\n\n\n\n\n\nData Pipelines\nAutoML\nMachine Learning Algorithms\nData Visualization\nMultiple Regression Analysis\n\n\n\n\nDescribe what you hope to achieve through your data science journey:\n\nShort term:\n\nImproved, robust project portfolio, proof of concept for job marketability\n\nLong-term career aspirations\n\nExpertise in AutoML, Agentic AI, ML algorithms\n\nTypes of problems I want to solve\n\nPredictive analytics, Geospacial data analysis, Time series analysis.\n\n\n\n\n\n\nEmail: jtevans9@byu.edu\nGitHub: https://github.com/Itswhatevans\nLinkedIn: https://linkedin.com/in/jordantevans\n\n\n\nHobbies - Disc golf - Social dance - Video games\nInterests - Music - Movies - Language - Planes/aeronautics - Astronomy\nFun Facts - Met my wife the same way her parents met: On the Ballroom Dance Touring company at BYU - Youngest of six kids - I was admitted to BYU three times\n\n\n\n\n\n\nHeadshot"
  },
  {
    "objectID": "about.html#goals",
    "href": "about.html#goals",
    "title": "About Me",
    "section": "",
    "text": "Describe what you hope to achieve through your data science journey:\n\nShort term:\n\nImproved, robust project portfolio, proof of concept for job marketability\n\nLong-term career aspirations\n\nExpertise in AutoML, Agentic AI, ML algorithms\n\nTypes of problems I want to solve\n\nPredictive analytics, Geospacial data analysis, Time series analysis."
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About Me",
    "section": "",
    "text": "Email: jtevans9@byu.edu\nGitHub: https://github.com/Itswhatevans\nLinkedIn: https://linkedin.com/in/jordantevans\n\n\n\nHobbies - Disc golf - Social dance - Video games\nInterests - Music - Movies - Language - Planes/aeronautics - Astronomy\nFun Facts - Met my wife the same way her parents met: On the Ballroom Dance Touring company at BYU - Youngest of six kids - I was admitted to BYU three times\n\n\n\n\n\n\nHeadshot"
  },
  {
    "objectID": "blogs/blog-tutorial.html",
    "href": "blogs/blog-tutorial.html",
    "title": "Blog Tutorial",
    "section": "",
    "text": "Have you ever been given a dataset and quickly found it to so messy you couldn’t even analyzy it? We’ll be examining how to use the Pandas package in Python to tackle and wrangle a dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudentName\nMajor\nGradYear\nGPA\nInternship?\nHoursWorked\n\n\n\n\nAlice Smith\nstatistics\n2026\n3.8\nYes\n12\n\n\nbob jones\nData Sci\n2025\n3.45\nyes\n15\n\n\nCAROL LEE\nSTATISTICS\n2026\nNaN\nNo\n8\n\n\nDavid Kim\ndata science\n2024\n3.92\nNo\nNaN\n\n\nEva Brown\nStats\n2025\n3.6\nYES\n20\n\n\n\n\nNotice the inconsistencies in the varying cell values. What can you see right away that could pose problems? ### Here are the issues that need fixing:\nInconsistent capitalization\nColumn names that don’t follow “snake_case”\nMixed Boolean values (Yes, YES, yes)\nMissing values\nAbbreviated Categories\nA column we might remove later"
  },
  {
    "objectID": "blogs/blog-tutorial.html#introduction",
    "href": "blogs/blog-tutorial.html#introduction",
    "title": "Blog Tutorial",
    "section": "",
    "text": "Have you ever been given a dataset and quickly found it to so messy you couldn’t even analyzy it? We’ll be examining how to use the Pandas package in Python to tackle and wrangle a dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudentName\nMajor\nGradYear\nGPA\nInternship?\nHoursWorked\n\n\n\n\nAlice Smith\nstatistics\n2026\n3.8\nYes\n12\n\n\nbob jones\nData Sci\n2025\n3.45\nyes\n15\n\n\nCAROL LEE\nSTATISTICS\n2026\nNaN\nNo\n8\n\n\nDavid Kim\ndata science\n2024\n3.92\nNo\nNaN\n\n\nEva Brown\nStats\n2025\n3.6\nYES\n20\n\n\n\n\nNotice the inconsistencies in the varying cell values. What can you see right away that could pose problems? ### Here are the issues that need fixing:\nInconsistent capitalization\nColumn names that don’t follow “snake_case”\nMixed Boolean values (Yes, YES, yes)\nMissing values\nAbbreviated Categories\nA column we might remove later"
  },
  {
    "objectID": "blogs/blog-tutorial.html#pattern-overview",
    "href": "blogs/blog-tutorial.html#pattern-overview",
    "title": "Blog Tutorial",
    "section": "Pattern Overview:",
    "text": "Pattern Overview:\n\nStandardize column names\nFix capitalization inconsistencies\nConvert data types\nRemove unnecessary columns\nHandle missing values\nAdd a clean index column"
  },
  {
    "objectID": "blogs/blog-tutorial.html#hit-em-with-this",
    "href": "blogs/blog-tutorial.html#hit-em-with-this",
    "title": "Blog Tutorial",
    "section": "Hit ’em with this!",
    "text": "Hit ’em with this!\n\nFirst we need some data:\nimport pandas as pd\n\n# Use pd.DataFrame()\ndf = pd.DataFrame({\n    \"StudentName\": [\"Alice Smith\", \"bob jones\", \"CAROL LEE\", \n    \"David Kim\", \"Eva Brown\"],\n    \"Major\": [\"statistics\", \"Data Sci\", \"STATISTICS\", \n    \"data science\", \"Stats\"],\n    \"GradYear\": [2026, 2025, 2026, 2024, 2025],\n    \"GPA\": [3.8, 3.45, None, 3.92, 3.6],\n    \"Internship?\": [\"Yes\", \"yes\", \"No\", \"No\", \"YES\"],\n    \"HoursWorked\": [12, 15, 8, None, 20]\n})\n\n\nStep 1: Clean up the Column Names\n# Use the Pandas '.rename()' method\ndf = df.rename(columns={\n    \"StudentName\": \"student_name\",\n    \"Major\": \"major\",\n    \"GradYear\": \"grad_year\",\n    \"GPA\": \"gpa\",\n    \"Internship?\": \"internship\",\n    \"HoursWorked\": \"hours_worked\"\n})\n\n\nStep 2: Standardize Text Values\n# Use 'str.title()', 'str.lower()' to standardize:\ndf[\"student_name\"] = df[\"student_name\"].str.title()\ndf[\"major\"] = df[\"major\"].str.lower()\ndf[\"internship\"] = df[\"internship\"].str.lower()\n\n\nStep 2a: Standardize Majors\n# Pandas '.replace()' method is great here, just put the column name in the [] brackets and add the current name before the colon \":\" with the desired new value after the colon \":\".\ndf[\"major\"] = df[\"major\"].replace({\n    \"data sci\": \"data science\",\n    \"stats\": \"statistics\"\n})\n\n\nStep 3: Convert Data Types\n# We're going to remap how we display whether students completed an internship to the established standard:\ndf[\"internship\"] = df[\"internship\"].map({\n    \"yes\": True,\n    \"no\": False\n})\n# Fun Fact: Boolean values are very versatile and can be utilized in other functions without having to encode 'yes' and 'no' into queries.\n# Next, we specify graduation year as integers:\ndf[\"grad_year\"] = df[\"grad_year\"].astype(int)\n\n\nStep 4: Handle Missing Values\n# Drop rows where GPA is missing:\n#   **We do this for datasets that are large enough to afford a few missing observations for other columns.**\ndf = df.dropna(subset=[\"gpa\"])\n\n# In other cases, we can translate missing values to a something more useful, like hours worked:\ndf[\"hours_worked\"] = df[\"hours_worked\"].fillna(0)\n\n\nStep 5: Remove Unnecessary Columns\n# OR: If we decide the whole column isn't useful, we can drop it:\ndf = df.drop(columns=[\"hours_worked\"])\n\n\nStep 6: Add a Clean Index Column;\n# If some of our analyses require tracking each row, it can be useful if their indices are displayed as their own column:\ndf = df.reset_index(drop=True)\ndf.insert(0, \"student_id\", range(1, len(df) + 1))"
  },
  {
    "objectID": "blogs/blog-tutorial.html#your-final-table-should-look-something-like-this",
    "href": "blogs/blog-tutorial.html#your-final-table-should-look-something-like-this",
    "title": "Blog Tutorial",
    "section": "Your Final Table Should Look Something Like This:",
    "text": "Your Final Table Should Look Something Like This:\n\n\n\nstudent_id\nstudent_name\nmajor\ngrad_year\ngpa\ninternship\n\n\n\n\n1\nAlice Smith\nstatistics\n2026\n3.8\nTrue\n\n\n2\nBob Jones\ndata science\n2025\n3.45\nTrue\n\n\n3\nDavid Kim\ndata science\n2024\n3.92\nFalse\n\n\n4\nEva Brown\nstatistics\n2025\n3.6\nTrue"
  },
  {
    "objectID": "blogs/blog-tutorial.html#conclusion-and-call-to-action",
    "href": "blogs/blog-tutorial.html#conclusion-and-call-to-action",
    "title": "Blog Tutorial",
    "section": "Conclusion and Call to Action",
    "text": "Conclusion and Call to Action\nTry applying this 6-step workflow to your own messy CSV file. What patterns repeat? What new cleaning rules do you need? Data cleaning is less about memorizing commands and more about building repeatable structure.\nNext time you open a messy dataset, try asking: 1. Are the column names consistent? 2. Are categories standardized? 3. Are data types correct? 4. What missing values matter?\n\nThanks for joining me on this tutorial! Check back regularly for more coding tips!"
  },
  {
    "objectID": "projects/data-acquisition.html",
    "href": "projects/data-acquisition.html",
    "title": "",
    "section": "",
    "text": "Code",
    "crumbs": [
      "data-acquisition.html"
    ]
  },
  {
    "objectID": "projects/final-project.html",
    "href": "projects/final-project.html",
    "title": "",
    "section": "",
    "text": "Code",
    "crumbs": [
      "final-project.html"
    ]
  }
]